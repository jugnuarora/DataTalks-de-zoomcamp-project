{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init() #This line initializes findspark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SPARK_HOME'] = \"/opt/homebrew/Cellar/apache-spark/3.5.4/libexec\" #Or your spark home.\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import functions as F\n",
    "#from pyspark.sql import types as T\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import types\n",
    "#from deep_translator import GoogleTranslator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials_location = './gcs.json'\n",
    "\n",
    "conf = SparkConf() \\\n",
    "    .setMaster('local[*]') \\\n",
    "    .setAppName('test') \\\n",
    "    .set(\"spark.jars\", \"./lib/gcs-connector-hadoop3-2.2.5.jar\") \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", credentials_location) \\\n",
    "    .set(\"spark.driver.extraClassPath\", \"./lib/gcs-connector-hadoop3-2.2.5.jar\") \\\n",
    "    .set(\"spark.executor.extraClassPath\", \"./lib/gcs-connector-hadoop3-2.2.5.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "hadoop_conf = sc._jsc.hadoopConfiguration()\n",
    "\n",
    "hadoop_conf.set(\"fs.AbstractFileSystem.gs.impl\",  \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "hadoop_conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.json.keyfile\", credentials_location)\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.enable\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .config(conf=sc.getConf()) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "#.config(conf=sc.getConf()) \\\n",
    "#.config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_courses = spark.read.option(\"header\", \"true\").parquet('gs://jugnu-france-course-enrollments/courses_enrol_data_2025_03_24/courses_raw_parquet/*.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/24 13:39:06 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 2:============================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------------+--------------------+----------------+---------------+---------+----------------------+-------------------------------+----------------+----------------+----------------+----------------+----------------+--------------------------------+-----------+-----------+-----------+-----------+-----------+--------------------+-------------+-------------+----------+----------+----------+---------------+--------------+--------------------+------------------+--------------------+--------------------+--------------------+----------------------------+---------+-----------------+---------------------+-----------------------+-----------------------+------------------------+-----------------+-----------------+------------------+----------------+-----------+-----------------+-----------------+\n",
      "|date_extract|      nom_of|   nom_departement|          nom_region|type_referentiel|code_inventaire|code_rncp|intitule_certification|libelle_niveau_sortie_formation|code_formacode_1|code_formacode_2|code_formacode_3|code_formacode_4|code_formacode_5|libelle_code_formacode_principal|code_rome_1|code_rome_2|code_rome_3|code_rome_4|code_rome_5|       libelle_nsf_1|libelle_nsf_2|libelle_nsf_3|code_nsf_1|code_nsf_2|code_nsf_3|code_certifinfo|         siret|    numero_formation|intitule_formation|        points_forts|  objectif_formation|   contenu_formation|resultats_attendus_formation|nb_action|nb_session_active|nb_session_a_distance|nombre_heures_total_min|nombre_heures_total_max|nombre_heures_total_mean|frais_ttc_tot_min|frais_ttc_tot_max|frais_ttc_tot_mean|code_departement|code_region|nbaction_nbheures|coderegion_export|\n",
      "+------------+------------+------------------+--------------------+----------------+---------------+---------+----------------------+-------------------------------+----------------+----------------+----------------+----------------+----------------+--------------------------------+-----------+-----------+-----------+-----------+-----------+--------------------+-------------+-------------+----------+----------+----------+---------------+--------------+--------------------+------------------+--------------------+--------------------+--------------------+----------------------------+---------+-----------------+---------------------+-----------------------+-----------------------+------------------------+-----------------+-----------------+------------------+----------------+-----------+-----------------+-----------------+\n",
      "|  2025-03-24|BT FORMATION|       Haute-Loire|Auvergne-Rhône-Alpes|              RS|           6965|       -1|  Créer et gérer de...|                           NULL|            NULL|            NULL|            NULL|            NULL|            NULL|                            NULL|       NULL|       NULL|       NULL|       NULL|       NULL|Informatique, tra...|         NULL|         NULL|     326.0|      NULL|      NULL|             -1|48121600000044|48121600000044_11...|LOGICIEL WORDPRESS|<p>24 ans d'expér...|<ul><li>Maitriser...|<p>WordPress est ...|        <p>La certificati...|        1|                1|                    0|                     30|                     30|                      30|           1490.0|           1490.0|            1490.0|              43|         84|               30|               84|\n",
      "|  2025-03-24|BT FORMATION|            Loiret| Centre-Val de Loire|              RS|           6965|       -1|  Créer et gérer de...|                           NULL|            NULL|            NULL|            NULL|            NULL|            NULL|                            NULL|       NULL|       NULL|       NULL|       NULL|       NULL|Informatique, tra...|         NULL|         NULL|     326.0|      NULL|      NULL|             -1|48121600000044|48121600000044_11...|LOGICIEL WORDPRESS|<p>24 ans d'expér...|<ul><li>Maitriser...|<p>WordPress est ...|        <p>La certificati...|        1|                1|                    0|                     30|                     30|                      30|           1490.0|           1490.0|            1490.0|              45|         24|               30|               24|\n",
      "|  2025-03-24|BT FORMATION|Meurthe-et-Moselle|           Grand Est|              RS|           6965|       -1|  Créer et gérer de...|                           NULL|            NULL|            NULL|            NULL|            NULL|            NULL|                            NULL|       NULL|       NULL|       NULL|       NULL|       NULL|Informatique, tra...|         NULL|         NULL|     326.0|      NULL|      NULL|             -1|48121600000044|48121600000044_11...|LOGICIEL WORDPRESS|<p>24 ans d'expér...|<ul><li>Maitriser...|<p>WordPress est ...|        <p>La certificati...|        1|                1|                    0|                     30|                     30|                      30|           1490.0|           1490.0|            1490.0|              54|         44|               30|               44|\n",
      "|  2025-03-24|BT FORMATION|              Nord|     Hauts-de-France|              RS|           6965|       -1|  Créer et gérer de...|                           NULL|            NULL|            NULL|            NULL|            NULL|            NULL|                            NULL|       NULL|       NULL|       NULL|       NULL|       NULL|Informatique, tra...|         NULL|         NULL|     326.0|      NULL|      NULL|             -1|48121600000044|48121600000044_11...|LOGICIEL WORDPRESS|<p>24 ans d'expér...|<ul><li>Maitriser...|<p>WordPress est ...|        <p>La certificati...|        1|                1|                    0|                     30|                     30|                      30|           1490.0|           1490.0|            1490.0|              59|         32|               30|               32|\n",
      "|  2025-03-24|BT FORMATION|            Savoie|Auvergne-Rhône-Alpes|              RS|           6965|       -1|  Créer et gérer de...|                           NULL|            NULL|            NULL|            NULL|            NULL|            NULL|                            NULL|       NULL|       NULL|       NULL|       NULL|       NULL|Informatique, tra...|         NULL|         NULL|     326.0|      NULL|      NULL|             -1|48121600000044|48121600000044_11...|LOGICIEL WORDPRESS|<p>24 ans d'expér...|<ul><li>Maitriser...|<p>WordPress est ...|        <p>La certificati...|        1|                1|                    0|                     30|                     30|                      30|           1490.0|           1490.0|            1490.0|              73|         84|               30|               84|\n",
      "+------------+------------+------------------+--------------------+----------------+---------------+---------+----------------------+-------------------------------+----------------+----------------+----------------+----------------+----------------+--------------------------------+-----------+-----------+-----------+-----------+-----------+--------------------+-------------+-------------+----------+----------+----------+---------------+--------------+--------------------+------------------+--------------------+--------------------+--------------------+----------------------------+---------+-----------------+---------------------+-----------------------+-----------------------+------------------------+-----------------+-----------------+------------------+----------------+-----------+-----------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_courses.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_courses.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema = types.StructType([\n",
    "#     types.StructField('date_extract', types.StringType(), True), \n",
    "#     types.StructField('nom_of', types.StringType(), True), \n",
    "#     types.StructField('nom_departement', types.StringType(), True), \n",
    "#     types.StructField('nom_region', types.StringType(), True), \n",
    "#     types.StructField('type_referentiel', types.StringType(), True), \n",
    "#     types.StructField('code_inventaire', types.LongType(), True), \n",
    "#     types.StructField('code_rncp', types.LongType(), True), \n",
    "#     types.StructField('intitule_certification', types.StringType(), True), \n",
    "#     types.StructField('libelle_niveau_sortie_formation', types.StringType(), True), \n",
    "#     types.StructField('code_formacode_1', types.DoubleType(), True), \n",
    "#     types.StructField('code_formacode_2', types.DoubleType(), True), \n",
    "#     types.StructField('code_formacode_3', types.DoubleType(), True), \n",
    "#     types.StructField('code_formacode_4', types.DoubleType(), True), \n",
    "#     types.StructField('code_formacode_5', types.DoubleType(), True), \n",
    "#     types.StructField('libelle_code_formacode_principal', types.StringType(), True), \n",
    "#     types.StructField('code_rome_1', types.StringType(), True), \n",
    "#     types.StructField('code_rome_2', types.StringType(), True), \n",
    "#     types.StructField('code_rome_3', types.StringType(), True), \n",
    "#     types.StructField('code_rome_4', types.StringType(), True), \n",
    "#     types.StructField('code_rome_5', types.StringType(), True), \n",
    "#     types.StructField('libelle_nsf_1', types.StringType(), True), \n",
    "#     types.StructField('libelle_nsf_2', types.StringType(), True), \n",
    "#     types.StructField('libelle_nsf_3', types.StringType(), True), \n",
    "#     types.StructField('code_nsf_1', types.StringType(), True), \n",
    "#     types.StructField('code_nsf_2', types.StringType(), True), \n",
    "#     types.StructField('code_nsf_3', types.StringType(), True), \n",
    "#     types.StructField('code_certifinfo', types.StringType(), True), \n",
    "#     types.StructField('siret', types.StringType(), True), \n",
    "#     types.StructField('numero_formation', types.StringType(), True), \n",
    "#     types.StructField('intitule_formation', types.StringType(), True), \n",
    "#     types.StructField('points_forts', types.StringType(), True), \n",
    "#     types.StructField('objectif_formation', types.StringType(), True), \n",
    "#     types.StructField('contenu_formation', types.StringType(), True), \n",
    "#     types.StructField('resultats_attendus_formation', types.StringType(), True), \n",
    "#     types.StructField('nb_action', types.IntegerType(), True), \n",
    "#     types.StructField('nb_session_active', types.IntegerType(), True), \n",
    "#     types.StructField('nb_session_a_distance', types.IntegerType(), True), \n",
    "#     types.StructField('nombre_heures_total_min', types.IntegerType(), True), \n",
    "#     types.StructField('nombre_heures_total_max', types.IntegerType(), True), \n",
    "#     types.StructField('nombre_heures_total_mean', types.IntegerType(), True), \n",
    "#     types.StructField('frais_ttc_tot_min', types.FloatType(), True), \n",
    "#     types.StructField('frais_ttc_tot_max', types.FloatType(), True), \n",
    "#     types.StructField('frais_ttc_tot_mean', types.FloatType(), True), \n",
    "#     types.StructField('code_departement', types.StringType(), True), \n",
    "#     types.StructField('code_region', types.StringType(), True), \n",
    "#     types.StructField('nbaction_nbheures', types.IntegerType(), True), \n",
    "#     types.StructField('coderegion_export', types.StringType(), True)\n",
    "#     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_courses_s = spark.read.option(\"header\", \"true\").schema(schema).parquet('gs://jugnu-france-course-enrollments/courses_data/courses_raw_parquet/*.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast the 'code_inventaire' column to a string\n",
    "df_courses = df_courses.withColumn(\"code_inventaire\", df_courses[\"code_inventaire\"].cast(types.StringType()))\\\n",
    "    .withColumn(\"code_rncp\", df_courses[\"code_rncp\"].cast(types.StringType()))\\\n",
    "    .withColumn(\"code_formacode_1\", F.regexp_replace(df_courses[\"code_formacode_1\"].cast(types.StringType()), r'\\.0$', '')) \\\n",
    "    .withColumn(\"code_formacode_2\", F.regexp_replace(df_courses[\"code_formacode_2\"].cast(types.StringType()), r'\\.0$', '')) \\\n",
    "    .withColumn(\"code_formacode_3\", F.regexp_replace(df_courses[\"code_formacode_3\"].cast(types.StringType()), r'\\.0$', '')) \\\n",
    "    .withColumn(\"code_formacode_4\", F.regexp_replace(df_courses[\"code_formacode_4\"].cast(types.StringType()), r'\\.0$', '')) \\\n",
    "    .withColumn(\"code_formacode_5\", F.regexp_replace(df_courses[\"code_formacode_5\"].cast(types.StringType()), r'\\.0$', '')) \\\n",
    "    .withColumn(\"code_nsf_1\", df_courses[\"code_nsf_1\"].cast(types.StringType()))\\\n",
    "    .withColumn(\"code_nsf_2\", df_courses[\"code_nsf_2\"].cast(types.StringType()))\\\n",
    "    .withColumn(\"code_nsf_3\", df_courses[\"code_nsf_3\"].cast(types.StringType()))\\\n",
    "    .withColumn(\"code_certifinfo\", df_courses[\"code_certifinfo\"].cast(types.StringType()))\\\n",
    "    .withColumn(\"siret\", df_courses[\"siret\"].cast(types.StringType()))\\\n",
    "    .withColumn(\"cost_max\", df_courses[\"frais_ttc_tot_max\"].cast(types.DecimalType(10, 2)))\\\n",
    "    .withColumn(\"cost_min\", df_courses[\"frais_ttc_tot_min\"].cast(types.DecimalType(10, 2)))\\\n",
    "    .withColumn(\"cost_mean\", df_courses[\"frais_ttc_tot_mean\"].cast(types.DecimalType(10, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(date_extract='2025-03-24', nom_of='BT FORMATION', nom_departement='Haute-Loire', nom_region='Auvergne-Rhône-Alpes', type_referentiel='RS', code_inventaire='6965', code_rncp='-1', intitule_certification='Créer et gérer des sites web avec WordPress (Tosa)', libelle_niveau_sortie_formation=None, code_formacode_1=None, code_formacode_2=None, code_formacode_3=None, code_formacode_4=None, code_formacode_5=None, libelle_code_formacode_principal=None, code_rome_1=None, code_rome_2=None, code_rome_3=None, code_rome_4=None, code_rome_5=None, libelle_nsf_1=\"Informatique, traitement de l'information, réseaux de transmission\", libelle_nsf_2=None, libelle_nsf_3=None, code_nsf_1='326.0', code_nsf_2=None, code_nsf_3=None, code_certifinfo='-1', siret='48121600000044', numero_formation='48121600000044_11172-60', intitule_formation='LOGICIEL WORDPRESS', points_forts='<p>24 ans d\\'expérience à votre service.</p><p>- Durée, rythme selon vos disponibilités.</p><p>- Préparation et passage à la certification inclus.</p><h4>Intéressé(e) ? \"Demander un devis\"</h4>', objectif_formation=\"<ul><li>Maitriser l'interface</li><li>Utiliser les fonctionnalités basiques du logiciel.</li><li>Utiliser les fonctionnalités avancées du logiciel.</li><li><br /><h2>Atteindre le niveau le plus élevé possible en personnalisant les objectifs en fonction de votre projet et de votre niveau initial.</h2><p></p><ul><li>- Formation avec un <b>formateur expert dédié</b> selon vos disponibilités.</li><li>- Accès à notre plate-forme e-learning en illimité.</li><li>- Suivi pédagogique pendant 6 mois.</li></ul><h4>Besoin de conseils ?</h4><ul><li> - Contactez-nous au <b>0806 706 666</b> (appel gratuit non surtaxé)</li><li> - Réservez un entretien personnalisé de 15 min en copiant/collant le lien suivant dans votre navigateur : <b>cpf.bt-formation.fr</b></li><li> - Envoyez-nous un mail à <b>info@bt-formation.fr</b></li></ul></li><li>MAJ:03/03/25 08:42</li></ul>\", contenu_formation=\"<p>WordPress est un logiciel de gestion de contenu (CMS) permettant de créer rapidement et simplement des sites Web et de gérer leur contenu à partir d'une interface d'administration.</p><h2>Introduction à WordPress</h2><ul><li>Notions sur les CMS</li><li>Eléments nécessaires à la mise en place d'un site WordPress</li><li>Les possibilités de WordPress</li><li>Différences entre un blog et un site</li><li><h2>Installation de WordPress</h2></li><li>Téléchargement des fichiers</li><li>Notions d'hébergement (location serveur, mutualisé ou non)</li><li>Gestion du serveur d'hébergement en local</li><li>Préparation de la Base de Données MySQL</li><li>Envoi des fichiers sur le serveur local</li><li>Installation du CMS</li><li><h2>Le contenu d'un site WordPress</h2></li><li>Les articles</li><li>Les pages</li><li>Gestion du contenu multimédia (textes, photos, vidéos)</li><li>Les commentaires</li><li><h2>Les visuels de WordPress</h2></li><li>Choix d'un thème</li><li>Personnalisation d'un thème</li><li>Les menus</li><li>Les widgets</li><li><h2>Les extensions (plugins)</h2></li><li>Qu'est-ce qu'une extension ?</li><li>Les plugins utiles (sécurité, contact, référencement, mise en cache)</li><li><h2>Utilisateurs</h2></li><li>Gestion des inscriptions à son site WordPress</li><li>Gestion des droits des utilisateurs</li><li>Création d'utilisateurs</li><li><h2>Réglages</h2></li><li>Les réglages de base</li><li>Configuration des articles</li><li>Configuration des commentaires</li><li>Configuration des dimensions d'images</li></ul>\", resultats_attendus_formation=\"<p>La certification TOSA Wordpress repose sur un test en ligne qui permet l'évaluation complète des compétences des candidats dans l'utilisation du logiciel. La certification se passe en conditions d'examen dans un centre agréé ou à distance, via une solution intégrée d'e-surveillance. À l'issue du test, le candidat se voit attribuer un score (0 à 1000).</p><p>Score sur une échelle de 1 à 1000.</p><ul><li></li><li>Durée : 1 H</li><li>Délivrance de la certification si le score est supérieur à 551</li><li>Certification incluse dans le prix de la formation</li></ul>\", nb_action=1, nb_session_active=1, nb_session_a_distance=0, nombre_heures_total_min=30, nombre_heures_total_max=30, nombre_heures_total_mean=30, frais_ttc_tot_min=1490.0, frais_ttc_tot_max=1490.0, frais_ttc_tot_mean=1490.0, code_departement='43', code_region='84', nbaction_nbheures=30, coderegion_export='84', cost_max=Decimal('1490.00'), cost_min=Decimal('1490.00'), cost_mean=Decimal('1490.00')),\n",
       " Row(date_extract='2025-03-24', nom_of='BT FORMATION', nom_departement='Loiret', nom_region='Centre-Val de Loire', type_referentiel='RS', code_inventaire='6965', code_rncp='-1', intitule_certification='Créer et gérer des sites web avec WordPress (Tosa)', libelle_niveau_sortie_formation=None, code_formacode_1=None, code_formacode_2=None, code_formacode_3=None, code_formacode_4=None, code_formacode_5=None, libelle_code_formacode_principal=None, code_rome_1=None, code_rome_2=None, code_rome_3=None, code_rome_4=None, code_rome_5=None, libelle_nsf_1=\"Informatique, traitement de l'information, réseaux de transmission\", libelle_nsf_2=None, libelle_nsf_3=None, code_nsf_1='326.0', code_nsf_2=None, code_nsf_3=None, code_certifinfo='-1', siret='48121600000044', numero_formation='48121600000044_11172-60', intitule_formation='LOGICIEL WORDPRESS', points_forts='<p>24 ans d\\'expérience à votre service.</p><p>- Durée, rythme selon vos disponibilités.</p><p>- Préparation et passage à la certification inclus.</p><h4>Intéressé(e) ? \"Demander un devis\"</h4>', objectif_formation=\"<ul><li>Maitriser l'interface</li><li>Utiliser les fonctionnalités basiques du logiciel.</li><li>Utiliser les fonctionnalités avancées du logiciel.</li><li><br /><h2>Atteindre le niveau le plus élevé possible en personnalisant les objectifs en fonction de votre projet et de votre niveau initial.</h2><p></p><ul><li>- Formation avec un <b>formateur expert dédié</b> selon vos disponibilités.</li><li>- Accès à notre plate-forme e-learning en illimité.</li><li>- Suivi pédagogique pendant 6 mois.</li></ul><h4>Besoin de conseils ?</h4><ul><li> - Contactez-nous au <b>0806 706 666</b> (appel gratuit non surtaxé)</li><li> - Réservez un entretien personnalisé de 15 min en copiant/collant le lien suivant dans votre navigateur : <b>cpf.bt-formation.fr</b></li><li> - Envoyez-nous un mail à <b>info@bt-formation.fr</b></li></ul></li><li>MAJ:03/03/25 08:42</li></ul>\", contenu_formation=\"<p>WordPress est un logiciel de gestion de contenu (CMS) permettant de créer rapidement et simplement des sites Web et de gérer leur contenu à partir d'une interface d'administration.</p><h2>Introduction à WordPress</h2><ul><li>Notions sur les CMS</li><li>Eléments nécessaires à la mise en place d'un site WordPress</li><li>Les possibilités de WordPress</li><li>Différences entre un blog et un site</li><li><h2>Installation de WordPress</h2></li><li>Téléchargement des fichiers</li><li>Notions d'hébergement (location serveur, mutualisé ou non)</li><li>Gestion du serveur d'hébergement en local</li><li>Préparation de la Base de Données MySQL</li><li>Envoi des fichiers sur le serveur local</li><li>Installation du CMS</li><li><h2>Le contenu d'un site WordPress</h2></li><li>Les articles</li><li>Les pages</li><li>Gestion du contenu multimédia (textes, photos, vidéos)</li><li>Les commentaires</li><li><h2>Les visuels de WordPress</h2></li><li>Choix d'un thème</li><li>Personnalisation d'un thème</li><li>Les menus</li><li>Les widgets</li><li><h2>Les extensions (plugins)</h2></li><li>Qu'est-ce qu'une extension ?</li><li>Les plugins utiles (sécurité, contact, référencement, mise en cache)</li><li><h2>Utilisateurs</h2></li><li>Gestion des inscriptions à son site WordPress</li><li>Gestion des droits des utilisateurs</li><li>Création d'utilisateurs</li><li><h2>Réglages</h2></li><li>Les réglages de base</li><li>Configuration des articles</li><li>Configuration des commentaires</li><li>Configuration des dimensions d'images</li></ul>\", resultats_attendus_formation=\"<p>La certification TOSA Wordpress repose sur un test en ligne qui permet l'évaluation complète des compétences des candidats dans l'utilisation du logiciel. La certification se passe en conditions d'examen dans un centre agréé ou à distance, via une solution intégrée d'e-surveillance. À l'issue du test, le candidat se voit attribuer un score (0 à 1000).</p><p>Score sur une échelle de 1 à 1000.</p><ul><li></li><li>Durée : 1 H</li><li>Délivrance de la certification si le score est supérieur à 551</li><li>Certification incluse dans le prix de la formation</li></ul>\", nb_action=1, nb_session_active=1, nb_session_a_distance=0, nombre_heures_total_min=30, nombre_heures_total_max=30, nombre_heures_total_mean=30, frais_ttc_tot_min=1490.0, frais_ttc_tot_max=1490.0, frais_ttc_tot_mean=1490.0, code_departement='45', code_region='24', nbaction_nbheures=30, coderegion_export='24', cost_max=Decimal('1490.00'), cost_min=Decimal('1490.00'), cost_mean=Decimal('1490.00'))]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_courses.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the string to a timestamp with the correct format\n",
    "df_courses_data = df_courses.withColumn('date_extract', F.to_date(F.col('date_extract'), 'yyyy-MM-dd'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_courses_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is named df\n",
    "\n",
    "filter_values = [\n",
    "    \"Informatique, traitement de l'information, réseaux de transmission\",\n",
    "    \"Enseignement, formation\",\n",
    "    \"Commerce, vente\",\n",
    "    \"Comptabilite, gestion\",\n",
    "    \"Spécialités pluri-scientifiques\",\n",
    "    \"Spécialites plurivalentes de la communication et de l'information\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_courses_data = df_courses_data.filter(col(\"libelle_nsf_1\").isin(filter_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_courses.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to rename and their new names\n",
    "columns_to_rename = {\n",
    "    'nom_of': 'provider',\n",
    "    'siret': 'provider_ID',\n",
    "    'nom_region': 'region',\n",
    "    'nom_departement': 'department',\n",
    "    'intitule_certification': 'certification_title',\n",
    "    'libelle_niveau_sortie_formation': 'training_exit_level',\n",
    "    'libelle_code_formacode_principal': 'main_formacode_desc',\n",
    "    'libelle_nsf_1': 'nsf_code_1_desc',\n",
    "    'libelle_nsf_2': 'nsf_code_2_desc',\n",
    "    'libelle_nsf_3': 'nsf_code_3_desc',\n",
    "    'numero_formation': 'training_ID',\n",
    "    'intitule_formation': 'title',\n",
    "    'points_forts': 'strengths',\n",
    "    'nb_session_active': 'nb_active_session',\n",
    "    'nb_session_a_distance': 'nb_distant_session',\n",
    "    'nombre_heures_total_min': 'duration_min',\n",
    "    'nombre_heures_total_max': 'duration_max',\n",
    "    'nombre_heures_total_mean': 'duration_mean',\n",
    "    'frais_ttc_tot_min': 'cost_min',\n",
    "    'frais_ttc_tot_max': 'cost_max',\n",
    "    'frais_ttc_tot_mean': 'cost_mean'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "for old_name, new_name in columns_to_rename.items():\n",
    "    if old_name in df_courses_data.columns:\n",
    "        df_courses_data = df_courses_data.withColumnRenamed(old_name, new_name)\n",
    "    else:\n",
    "        print(f\"Column '{old_name}' not found, skipping rename.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_courses.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_courses_data.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_courses_data.coalesce(1).write.parquet('gs://jugnu-france-course-enrollments/courses_enrol_data_2025_03_20/courses_filtered', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S.unique_row_id, S.date_extract, S.provider, S.department, S.region, S.type_referential, S.code_rs, S.code_rncp, S.certification_title, S.training_exit_level, S.code_formacode_1, S.code_formacode_2, S.code_formacode_3, S.code_formacode_4, S.code_formacode_5, S.main_formacode_desc, S.code_rome_1, S.code_rome_2, S.code_rome_3, S.code_rome_4, S.code_rome_5, S.nsf_code_1_desc, S.nsf_code_2_desc, S.nsf_code_3_desc, S.nsf_code_1, S.nsf_code_2, S.nsf_code_3, S.code_certification, S.provider_id, S.training_id, S.training_title, S.strong_points, S.training_objective, S.training_content, S.expected_training_results, S.trianing_module_count, S.nb_session_active, S.nb_remote_session, S.duration_min, S.duration_max, S.duration_mean, S.fees_min, S.fees_max, S.fees_mean, S.department_code, S.region_code, S.nb_hours, S.coderegion_export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_batch(unique_values):\n",
    "    translations = {}\n",
    "    translator = GoogleTranslator(source='auto', target='en')\n",
    "    for value in unique_values:\n",
    "        if value is not None:\n",
    "            try:\n",
    "                translations[value] = translator.translate(value)\n",
    "            except Exception as e:\n",
    "                print(f\"Translation error: {e}\")\n",
    "                translations[value] = None\n",
    "        else:\n",
    "            translations[value] = None\n",
    "    return translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_translate = ['certification_title'] #, 'title', 'main_formacode_desc']\n",
    "translation_maps = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of partitions: {df_courses.rdd.getNumPartitions()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_courses = df_courses.repartition(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in columns_to_translate:\n",
    "    unique_values = [row[0] for row in df_courses.select(col_name).distinct().collect()]\n",
    "    translation_maps[col_name] = translate_batch(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in columns_to_translate:\n",
    "    translation_map = translation_maps[col_name]\n",
    "    broadcasted_map = sc.broadcast(translation_map)\n",
    "\n",
    "    @F.udf(returnType=T.StringType())\n",
    "    def lookup_translation(input_value):\n",
    "        return broadcasted_map.value.get(input_value)\n",
    "\n",
    "    df_courses = df_courses.withColumn(f'{col_name}_en', lookup_translation(F.col(col_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(returnType=T.StringType())\n",
    "def translate(input):\n",
    "    if input is None:\n",
    "        return None  # Or return \"\" if you prefer an empty string\n",
    "    try:\n",
    "        return GoogleTranslator(source='auto', target='en').translate(input)\n",
    "    except NotValidPayload:\n",
    "        return None #Or some other error handling.\n",
    "    except Exception as e:\n",
    "        print(f\"Translation error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_courses = df_courses\\\n",
    "            .withColumn('certification_title_en', translate(F.col('certification_title')))\\\n",
    "            .withColumn('title_en', translate(F.col('title')))\\\n",
    "            .withColumn('main_formacode_desc_en', translate(F.col('main_formacode_desc')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_courses.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_courses\\\n",
    "    .write\\\n",
    "    .parquet('gs://jugnu-france-course-enrollments/courses_data/courses_raw_parquet/france_courses_en.parquet', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gcsfs\n",
    "import os\n",
    "\n",
    "def read_parquet_from_gcs(gcs_path, credentials_path):\n",
    "    \"\"\"Reads a Parquet file from Google Cloud Storage into a pandas DataFrame.\"\"\"\n",
    "    try:\n",
    "        # Set the environment variable within the function\n",
    "        os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"gcs.json\"\n",
    "\n",
    "        fs = gcsfs.GCSFileSystem()\n",
    "        with fs.open(gcs_path) as f:\n",
    "            df = pd.read_parquet(f, )\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading Parquet file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "gcs_path = \"gs://your-bucket/path/to/your/file.parquet\"  # Replace with your GCS path\n",
    "credentials_path = \"gcs.json\"  # Replace with your path\n",
    "\n",
    "df = read_parquet_from_gcs(gcs_path, credentials_path)\n",
    "\n",
    "if df is not None:\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enrollments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enrollments = spark.read.option(\"header\", \"true\").parquet('gs://jugnu-france-course-enrollments/courses_enrol_data_2025_03_21/enrollments_raw_parquet/*.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enrollments.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enrollments.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enrollments.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast the 'code_inventaire' column to a string\n",
    "df_enrollments = df_enrollments\\\n",
    "    .withColumn('annee_mois', F.to_date(df_enrollments[\"annee_mois\"], \"yyyy-MM\"))\\\n",
    "    .withColumn(\"annee\", df_enrollments[\"annee\"].cast(types.StringType()))\\\n",
    "    .withColumn(\"mois\", df_enrollments[\"mois\"].cast(types.StringType()))\\\n",
    "    .withColumn(\"code_rncp\", df_enrollments[\"code_rncp\"].cast(types.StringType()))\\\n",
    "    .withColumn(\"code_rs\", df_enrollments[\"code_rs\"].cast(types.StringType()))\\\n",
    "    .withColumn(\"code_certifinfo\", df_enrollments[\"code_certifinfo\"].cast(types.StringType()))\\\n",
    "    .withColumn(\"siret_of_contractant\", df_enrollments[\"siret_of_contractant\"].cast(types.StringType()))\\\n",
    "    .withColumn(\"date_chargement\", F.to_date(df_enrollments[\"date_chargement\"], \"yyyy-MM-dd\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enrollments.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enrollments.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to rename and their new names\n",
    "columns_to_rename = {\n",
    "        'annee_mois': 'year_month',\n",
    "        'annee': 'year',\n",
    "        'mois': 'month',\n",
    "        'type_referentiel': 'type_referential',\n",
    "        'code_certifinfo': 'code_certification',\n",
    "        'intitule_certification': 'certification_title',\n",
    "        'siret_of_contractant': 'provider_ID',\n",
    "        'raison_sociale_of_contractant': 'provider',\n",
    "        'entrees_formation': 'training_entries',\n",
    "        'sorties_realisation_partielle': 'partial_completion_exits',\n",
    "        'sorties_realisation_totale': 'total_completion_exits',\n",
    "        'date_chargement': 'load_date'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "for old_name, new_name in columns_to_rename.items():\n",
    "    if old_name in df_enrollments.columns:\n",
    "        df_enrollments = df_enrollments.withColumnRenamed(old_name, new_name)\n",
    "    else:\n",
    "        print(f\"Column '{old_name}' not found, skipping rename.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enrollments.coalesce(1).write.parquet('gs://jugnu-france-course-enrollments/courses_enrol_data_2025_03_21/enrollments_filtered', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enrollments[\"year_month\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S.year_month, S.year, S.month, S.type_referential, S.code_rncp, S.code_rs, S.code_certification, S.certification_title, S.provider_id,\n",
    "S.provider, S.partial_achievement_exits, S.complete_achievement_exits, S.load_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formacode Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SPARK_HOME'] = \"/opt/homebrew/Cellar/apache-spark/3.5.4/libexec\" #Or your spark home.\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "#from pyspark.sql.functions import col\n",
    "#from pyspark.sql import types\n",
    "from deep_translator import GoogleTranslator\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials_location = './gcs.json'\n",
    "\n",
    "conf = SparkConf() \\\n",
    "    .setMaster('local[*]') \\\n",
    "    .setAppName('test-2') \\\n",
    "    .set(\"spark.jars\", \"./lib/gcs-connector-hadoop3-2.2.5.jar\") \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", credentials_location) \\\n",
    "    .set(\"spark.driver.extraClassPath\", \"./lib/gcs-connector-hadoop3-2.2.5.jar\") \\\n",
    "    .set(\"spark.executor.extraClassPath\", \"./lib/gcs-connector-hadoop3-2.2.5.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/24 10:52:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "hadoop_conf = sc._jsc.hadoopConfiguration()\n",
    "\n",
    "hadoop_conf.set(\"fs.AbstractFileSystem.gs.impl\",  \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "hadoop_conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.json.keyfile\", credentials_location)\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.enable\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .config(conf=sc.getConf()) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "#.config(conf=sc.getConf()) \\\n",
    "#.config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.sql import functions as F\n",
    "#from pyspark.sql import types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql import functions as F\n",
    "# from pyspark.sql import types as T\n",
    "\n",
    "# spark = ...\n",
    "\n",
    "# df = spark.createDataFrame([\n",
    "#     ['ich suche den namen'],\n",
    "#     ['guten tag']],\n",
    "#     ['name'])\n",
    "\n",
    "# @F.udf(returnType=T.StringType())\n",
    "# def translate(input):\n",
    "#    # from deep_translator import GoogleTranslator\n",
    "#     return GoogleTranslator(source='auto', target='en').translate(input)\n",
    "\n",
    "# df.withColumn('translation', translate(F.col('name'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formacode = spark.read\\\n",
    "                         .option(\"header\", \"true\") \\\n",
    "                         .csv(\"./data/formacode_description.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['formacode', 'description', 'field', 'generic_term']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_formacode.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Replace empty fields\n",
    "df_formacode = df_formacode.withColumn(\"field\", F.coalesce(F.col(\"field\"), F.lit(\"000 unknown\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formacode = df_formacode.repartition(16, \"field\")\n",
    "#df_formacode = df_formacode.repartition(\"field\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions: 16\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of partitions: {df_formacode.rdd.getNumPartitions()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(input_str):\n",
    "    if input_str and len(input_str) > 0: # Check for empty or None\n",
    "        try:\n",
    "            #time.sleep(0.3)\n",
    "            return GoogleTranslator(source='auto', target='en').translate(input_str)\n",
    "        except Exception as e:\n",
    "            print(f\"Translation error: {e}\")\n",
    "            return input_str # Return original string on error\n",
    "    else:\n",
    "        return \"\" # Return empty string for empty or None input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(returnType=T.StringType())\n",
    "def translate_udf(input_str): # udf, for dataframe columns.\n",
    "    return translate(input_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Collect unique values\n",
    "unique_fields = [x[0] for x in df_formacode.select(\"field\").distinct().collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Translate unique values\n",
    "field_translations = {field: translate(field) for field in unique_fields if field is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Broadcast dictionary\n",
    "broadcast_fields = sc.broadcast(field_translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create UDF to lookup values\n",
    "@F.udf(returnType=T.StringType())\n",
    "def lookup_translation(field):\n",
    "    return broadcast_fields.value.get(field, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formacode = df_formacode.withColumn('description_en', translate_udf(F.col('description')))\\\n",
    "    .withColumn(\"field_en\", lookup_translation(F.col(\"field\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|formacode|         description|               field|        generic_term|      description_en|            field_en|\n",
      "+---------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|    46054|industrie graphiq...|460 INDUSTRIE GRA...|00104 TECHNOLOGIE...|Printing graphics...|460 Imprimerie gr...|\n",
      "|    46072|       art graphique|460 INDUSTRIE GRA...|46054 INDUSTRIE G...|         graphic art|460 Imprimerie gr...|\n",
      "|    46081|  création graphique|460 INDUSTRIE GRA...| 46072 ART GRAPHIQUE|    graphic creation|460 Imprimerie gr...|\n",
      "|    46090| graphisme publicité|460 INDUSTRIE GRA...|46081 CREATION GR...|Advertising graphics|460 Imprimerie gr...|\n",
      "|    46003|         infographie|460 INDUSTRIE GRA...|46081 CREATION GR...|         infographic|460 Imprimerie gr...|\n",
      "|    46093|    chaîne graphique|460 INDUSTRIE GRA...|46054 INDUSTRIE G...|      graphics chain|460 Imprimerie gr...|\n",
      "|    46077| finition imprimerie|460 INDUSTRIE GRA...|46093 CHAINE GRAP...|     printing finish|460 Imprimerie gr...|\n",
      "|    46069|   dorure imprimerie|460 INDUSTRIE GRA...|46077 FINITION IM...|    printing gilding|460 Imprimerie gr...|\n",
      "|    46096| gaufrage imprimerie|460 INDUSTRIE GRA...|46077 FINITION IM...|  Printing waking up|460 Imprimerie gr...|\n",
      "|    46089|         massicotage|460 INDUSTRIE GRA...|46077 FINITION IM...|             massive|460 Imprimerie gr...|\n",
      "|    46079|   pliage imprimerie|460 INDUSTRIE GRA...|46077 FINITION IM...|    Printing folding|460 Imprimerie gr...|\n",
      "|    46098|reliure brochure ...|460 INDUSTRIE GRA...|46077 FINITION IM...|Industrial brochu...|460 Imprimerie gr...|\n",
      "|    46027|          impression|460 INDUSTRIE GRA...|46093 CHAINE GRAP...|          impression|460 Imprimerie gr...|\n",
      "|    46028|        flexographie|460 INDUSTRIE GRA...|    46027 IMPRESSION|        flexographie|460 Imprimerie gr...|\n",
      "|    46039|        héliogravure|460 INDUSTRIE GRA...|    46027 IMPRESSION|        heliogravure|460 Imprimerie gr...|\n",
      "|    46042|impression numérique|460 INDUSTRIE GRA...|    46027 IMPRESSION|    digital printing|460 Imprimerie gr...|\n",
      "|    46016|              offset|460 INDUSTRIE GRA...|    46027 IMPRESSION|              offset|460 Imprimerie gr...|\n",
      "|    46010|  qualité impression|460 INDUSTRIE GRA...|    46027 IMPRESSION|    Printing quality|460 Imprimerie gr...|\n",
      "|    46029|         sérigraphie|460 INDUSTRIE GRA...|    46027 IMPRESSION|     screen printing|460 Imprimerie gr...|\n",
      "|    46049|          pré-presse|460 INDUSTRIE GRA...|46093 CHAINE GRAP...|           pre-press|460 Imprimerie gr...|\n",
      "+---------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_formacode.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formacode.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formacode = df_formacode.repartition(16, \"field\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions: 16\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of partitions: {df_formacode.rdd.getNumPartitions()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Null field count: {df_formacode.filter(F.col('field').isNull()).count()}\")\n",
    "print(f\"Empty field count: {df_formacode.filter(F.col('field') == '').count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_formacode.coalesce(1).write.parquet('gs://jugnu-france-course-enrollments/formacode_converted', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.add_packages(\"com.google.cloud.spark:spark-bigquery-with-dependencies_2.12:0.34.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set('temporaryGcsBucket', 'jugnu-france-course-enrollments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update to your GCS bucket\n",
    "gcs_bucket = 'dataproc-bucket-name'\n",
    "\n",
    "# Update to your BigQuery dataset name you created\n",
    "bq_dataset = 'dataset_name'\n",
    "\n",
    "# Enter BigQuery table name you want to create or overwite. \n",
    "# If the table does not exist it will be created when you run the write function\n",
    "bq_table = 'wiki_total_pageviews'\n",
    "\n",
    "df_wiki_en_totals.write \\\n",
    "  .format(\"bigquery\") \\\n",
    "  .option(\"table\",\"{}.{}\".format(bq_dataset, bq_table)) \\\n",
    "  .option(\"temporaryGcsBucket\", gcs_bucket) \\\n",
    "  .mode('overwrite') \\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_write_bigquery(data = df_formacode,\n",
    "  projectId = \"france-courses-enrollments\",\n",
    "  datasetID = \"seed\",\n",
    "  tableID = \"formacode\",\n",
    "  mode = \"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formacode.write.format(\"bigquery\") \\\n",
    "      .option(\"credentialsFile\", \"./gcs.json\") \\\n",
    "      .option(\"table\", \"seed.formacode\") \\\n",
    "      .save()\n",
    "\n",
    "      #.option(\"temporaryGcsBucket\", \"jugnu-france-course-enrollments\") \\\n",
    "      #.option(\"project\", \"france-courses-enrollments\") \\\n",
    "      #.option(\"dataset\", \"seed\") \\\n",
    "\n",
    "            #.mode(\"overwrite\") \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Construct a BigQuery client object.\n",
    "client = bigquery.Client()\n",
    "\n",
    "# TODO(developer): Set table_id to the ID of table to append to.\n",
    "table_id = \"france-courses-enrollments.seed.test\"\n",
    "\n",
    "rows_to_insert = [\n",
    "    {\"full_name\": \"Phred Phlyntstone\", \"age\": 32},\n",
    "    {\"full_name\": \"Wylma Phlyntstone\", \"age\": 29},\n",
    "]\n",
    "\n",
    "errors = client.insert_rows_json(table_id, rows_to_insert)  # Make an API request.\n",
    "if errors == []:\n",
    "    print(\"New rows have been added.\")\n",
    "else:\n",
    "    print(\"Encountered errors while inserting rows: {}\".format(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formacode.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "def write_dataframe_to_bigquery(df: DataFrame, project_id: str, dataset_id: str, table_id: str, temp_gcs_bucket: str, gcs_credentials_path: str):\n",
    "    \"\"\"\n",
    "    Writes a Spark DataFrame to BigQuery using a local GCS credentials JSON file.\n",
    "\n",
    "    Args:\n",
    "        df: The Spark DataFrame to write.\n",
    "        project_id: The Google Cloud Project ID.\n",
    "        dataset_id: The BigQuery dataset ID.\n",
    "        table_id: The BigQuery table ID.\n",
    "        temp_gcs_bucket: A Google Cloud Storage bucket for temporary storage.\n",
    "        gcs_credentials_path: Path to the GCS credentials JSON file.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        spark.conf.set(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", \"./gcs.json\")\n",
    "        spark.conf.set(\"spark.hadoop.google.cloud.project\", project_id) #add this line\n",
    "\n",
    "        df.write \\\n",
    "            .format(\"bigquery\") \\\n",
    "            .option(\"temporaryGcsBucket\", temp_gcs_bucket) \\\n",
    "            .option(\"project\", project_id) \\\n",
    "            .option(\"dataset\", dataset_id) \\\n",
    "            .option(\"table\", table_id) \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .save()\n",
    "\n",
    "        print(f\"DataFrame written to BigQuery: {project_id}.{dataset_id}.{table_id}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing DataFrame to BigQuery: {e}\")\n",
    "        raise\n",
    "\n",
    "# Example usage (replace with your actual values):\n",
    "project_id = \"france-courses-enrollments\"\n",
    "dataset_id = \"seed\"\n",
    "table_id = \"formacode\"\n",
    "temp_gcs_bucket = \"jugnu-france-course-enrollments\"\n",
    "gcs_credentials_path = \"./gcs.json\"  # Path to your gcs.json file\n",
    "\n",
    "# Assuming you already have a SparkSession created:\n",
    "spark = SparkSession.builder.appName(\"WriteToBigQuery\").getOrCreate()\n",
    "\n",
    "# Assuming you have your DataFrame df_formacode:\n",
    "# df_formacode = ... (your DataFrame creation logic)\n",
    "\n",
    "# Sample dataframe creation for testing.\n",
    "data = [(\"Alice\", 34), (\"Bob\", 45), (\"Charlie\", 28)]\n",
    "df_formacode = spark.createDataFrame(data, [\"name\", \"age\"])\n",
    "\n",
    "#Ensure the gcs.json file exists\n",
    "if not os.path.exists(gcs_credentials_path):\n",
    "    raise FileNotFoundError(f\"GCS credentials file not found: {gcs_credentials_path}\")\n",
    "\n",
    "write_dataframe_to_bigquery(df_formacode, project_id, dataset_id, table_id, temp_gcs_bucket, gcs_credentials_path)\n",
    "\n",
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"VerifyConfig\").getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.hadoop.google.cloud.project\", \"france-courses-enrollments\")\n",
    "print(\"Project ID from Spark Conf:\", spark.conf.get(\"spark.hadoop.google.cloud.project\"))\n",
    "\n",
    "spark.conf.set(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", \"/./gcs.json\") #use absolute path\n",
    "print(\"Credentials Path from Spark Conf:\", spark.conf.get(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\"))\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"BigQueryWrite\")\\\n",
    "    .config(\"spark.jars.packages\", \"com.google.cloud.spark:spark-bigquery-with-dependencies:0.34.0\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"BigQueryReadTest\").getOrCreate()\n",
    "\n",
    "df = spark.read.format(\"bigquery\") \\\n",
    "    .option(\"table\", \"france-courses-enrollments.staging.courses\") \\\n",
    "    .load()\n",
    "df.show()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Set environment variables (do this at the VERY beginning of your notebook)\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = \"france-courses-enrollments\"\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/jugnuarora/neuefische_self/france_courses_enrollments/gcs.json\"  # Replace with your absolute path\n",
    "\n",
    "# Verify environment variables (optional)\n",
    "print(\"GOOGLE_CLOUD_PROJECT:\", os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
    "print(\"GOOGLE_APPLICATION_CREDENTIALS:\", os.environ.get(\"GOOGLE_APPLICATION_CREDENTIALS\"))\n",
    "\n",
    "# Create SparkSession and run your BigQuery code\n",
    "spark = SparkSession.builder.appName(\"BigQueryTest\").getOrCreate()\n",
    "\n",
    "# Example: Read from BigQuery (replace with your actual code)\n",
    "try:\n",
    "    df = spark.read.format(\"bigquery\") \\\n",
    "        .option(\"table\", \"france-courses-enrollments.staging.courses\") \\\n",
    "        .load()\n",
    "    df.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S.date_extract, S.provider, S.department, S.region, S.type_referentiel, S.code_inventaire, S.code_rncp, S.certification_title, S.training_exit_level, S.code_formacode_1, S.code_formacode_2, S.code_formacode_3, S.code_formacode_4, S.code_formacode_5, S.main_formacode_desc, S.code_rome_1, S.code_rome_2, S.code_rome_3, S.code_rome_4, S.code_rome_5, S.nsf_code_1_desc, S.nsf_code_2_desc, S.nsf_code_3_desc, S.code_nsf_1, S.code_nsf_2 S.code_nsf_3, S.code_certifinfo, S.provider_ID, S.training_ID S.title, S.strengths, S.objectif_formation, S.contenu_formation, S.resultats_attendus_formation, S.nb_action, S.nb_active_session, S.nb_distant_session, S.duration_min, S.duration_max, S.duration_mean, S.cost_min, S.cost_max, S.cost_mean, S.code_departement, S.code_region, S.nbaction_nbheures, S.coderegion_export"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
